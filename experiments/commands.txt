=========================================
TESTING SMALL DATASET WITH NOHUP

nohup accelerate launch --config_file config/accelerate_local.yaml \
scripts/train_unet.py \
--dataset_name cache/spotify_sleep_dataset/waveform_small/mel_spectrogram \
--hop_length 256 \
--n_fft 1024 \
--output_dir models/ssd_light_training_waveform_small_64_64 \
--train_batch_size 4 \
--eval_batch_size 8 \
--num_epochs 8 \
--gradient_accumulation_steps 4 \
--learning_rate 1e-4 \
--lr_warmup_steps 500 \
--mixed_precision no \
--save_model_epochs 2 \
--save_images_epochs 2 \
--num_train_steps 1000 \
--num_inference_steps 1000 \
--train_scheduler ddpm \
--test_scheduler ddpm \
> logs/ssd_light_training_waveform_small_64_64 2>&1 &

=========================================
GENERATE MEL SPECTROGRAMS FROM AUDIO AND SAVE TO File

nohup python scripts/audio_to_images.py \
--resolution 256,256 \
--hop_length 256 \
--n_fft 1024 \
--mel_spec_method image \
--input_dir cache/spotify_sleep_dataset/waveform_sleep_only \
--output_dir cache/spotify_sleep_dataset/waveform_sleep_only/mel_spec_256_256_so \
--sample_rate 22050 \
--num_channels 1 \
> logs/mel_spec_256_256_so.log 2>&1 &

nohup python scripts/audio_to_images.py \
--resolution 512,128 \
--hop_length 256 \
--n_fft 1024 \
--mel_spec_method bigvgan \
--bigvgan_model bigvgan_v2_44khz_128band_256x \
--input_dir cache/spotify_sleep_dataset/waveform \
--output_dir cache/spotify_sleep_dataset/waveform/bigvgan_512_128 \
--sample_rate 44100 \
--num_channels 1 \
> logs/mel_spec_bigvgan_512_128.log 2>&1 &

nohup python scripts/audio_to_images.py \
--resolution 512,128 \
--hop_length 256 \
--n_fft 1024 \
--mel_spec_method image \
--input_dir cache/spotify_sleep_dataset/waveform_selection_1024 \
--output_dir cache/spotify_sleep_dataset/waveform_selection_1024/ \
--sample_rate 44100 \
--num_channels 1 \
> logs/mel_spec_bigvgan_512_128.log 2>&1 &

# check frequency range matches
# check n_fft

# generating for alternative mel-spectrogram resolutions

nohup python scripts/audio_to_images.py \
--resolution 512,128 \
--hop_length 256 \
--n_fft 512 \
--mel_spec_method bigvgan \
--bigvgan_model bigvgan_v2_44khz_128band_256x \
--input_dir cache/spotify_sleep_dataset/waveform_sleep_only \
--output_dir cache/spotify_sleep_dataset/final_dataset/bigvgan_512_128_hl256_nfft512_sleep_only \
--sample_rate 44100 \
--num_channels 1 \
> logs/mel_spec_bigvgan_512_128_hl256_nfft512_sleep_only.log 2>&1 &

nohup python scripts/audio_to_images.py \
--resolution 512,128 \
--hop_length 128 \
--n_fft 512 \
--mel_spec_method bigvgan \
--bigvgan_model bigvgan_v2_44khz_128band_256x \
--input_dir cache/spotify_sleep_dataset/waveform_sleep_only \
--output_dir cache/spotify_sleep_dataset/final_datasets/bigvgan_512_128_hl128_nfft512_sleep_only \
--sample_rate 44100 \
--num_channels 1 \
> logs/mel_spec_bigvgan_512_128_hl128_nfft512_sleep_only.log 2>&1 &

nohup python scripts/audio_to_images.py \
--resolution 512,128 \
--hop_length 256 \
--n_fft 512 \
--mel_spec_method image \
--input_dir cache/spotify_sleep_dataset/waveform_sleep_only \
--output_dir cache/spotify_sleep_dataset/final_datasets/mel_spec_512_128_hl256_nfft512_sleep_only \
--sample_rate 22050 \
--num_channels 1 \
> logs/mel_spec_512_128_hl256_nfft512_sleep_only.log 2>&1 &

nohup python scripts/audio_to_images.py \
--resolution 512,128 \
--hop_length 128 \
--n_fft 512 \
--mel_spec_method image \
--input_dir cache/spotify_sleep_dataset/waveform_sleep_only \
--output_dir cache/spotify_sleep_dataset/final_datasets/mel_spec_512_128_hl128_nfft512_sleep_only \
--sample_rate 22050 \
--num_channels 1 \
> logs/mel_spec_512_128_hl128_nfft512_sleep_only.log 2>&1 &

nohup python scripts/audio_to_images.py \
--resolution 512,128 \
--hop_length 512 \
--n_fft 1024 \
--mel_spec_method image \
--input_dir cache/spotify_sleep_dataset/waveform_sleep_only \
--output_dir cache/spotify_sleep_dataset/final_datasets/mel_spec_512_128_hl512_nfft1024_sleep_only \
--sample_rate 22050 \
--num_channels 1 \
> logs/mel_spec_512_128_hl512_nfft1024_sleep_only.log 2>&1 &

=========================================
lengthen audios to a target length

nohup python scripts/lengthen_audio.py \
--input_dir cache/spotify_sleep_dataset/waveform \
--output_dir cache/spotify_sleep_dataset/waveform_lengthened \
--target_length 100 \
> logs/lengthen_audio_to_100.log 2>&1 &



=========================================
GENERATE SAMPLE IMAGES FROM TRAINED MODEL

python scripts/inference_unet.py \
--model_path path/to/model \
--num_images 512 \
--num_inference_steps 50 \
--eval_batch_size 64 \
--scheduler ddim

=========================================
COMPUTE FAD SCORE BETWEEN REFERENCE AND GENERATED SET

fadtk clap-laion-audio /path/to/baseline/audio /path/to/evaluation/audio

=========================================
TRAIN VAE

nohup python scripts/train_vae.py \
    --dataset_name cache/spotify_sleep_dataset/waveform_small/mel_spec_64_64 \
    --batch_size 8 \
    --gradient_accumulation_steps 2 \
    --save_images_batches 4 \
    --max_epochs 200 > logs/train_vae_ssd_64 2>&1 &


=========================================
#numpy version 1.23.5

COMPUTE HOW MANY FAD SAMPLES evaluation
python scripts/how_many_samples_for_fad_evaluation.py \
    --reference_paths cache/spotify_sleep_dataset/waveform cache/fma_pop/waveform cache/musiccaps/waveform \
    --generated_paths models/ssd_64_64/model_step_40000/samples/audio/sch_ddpm_nisteps_1000 \
                      models/ssd_64_64/model_step_40000/samples/audio/sch_ddpm_nisteps_1000_102 \
                      models/ssd_64_64/model_step_40000/samples/audio/sch_ddpm_nisteps_1000_1024 \
                      models/ssd_64_64/model_step_40000/samples/audio/sch_ddpm_nisteps_1000_1228 \
                      models/ssd_64_64/model_step_40000/samples/audio/sch_ddpm_nisteps_1000_1433 \
                      models/ssd_64_64/model_step_40000/samples/audio/sch_ddpm_nisteps_1000_1638 \
                      models/ssd_64_64/model_step_40000/samples/audio/sch_ddpm_nisteps_1000_1843 \
                      models/ssd_64_64/model_step_40000/samples/audio/sch_ddpm_nisteps_1000_204 \
                      models/ssd_64_64/model_step_40000/samples/audio/sch_ddpm_nisteps_1000_409 \
                      models/ssd_64_64/model_step_40000/samples/audio/sch_ddpm_nisteps_1000_51 \
                      models/ssd_64_64/model_step_40000/samples/audio/sch_ddpm_nisteps_1000_614 \
                      models/ssd_64_64/model_step_40000/samples/audio/sch_ddpm_nisteps_1000_819 \
    --metric frechet_audio_distance \
    --model_names clap-laion-audio clap-laion-music vggish


=========================================


=========================================


=========================================


write me a python script which will loop over certain variables for the following command:

accelerate launch --config_file config/accelerate_local.yaml \
scripts/train_unet.py \
--dataset_name cache/spotify_sleep_dataset/waveform_small/mel_spectrogram \
--hop_length 256 \
--n_fft 1024 \
--output_dir models/ssd_light_training_waveform_small_64_64 \
--train_batch_size 32 \
--eval_batch_size 8 \
--num_epochs 1000 \
--gradient_accumulation_steps 4 \
--learning_rate 1e-4 \
--lr_warmup_steps 500 \
--mixed_precision no \
--save_model_epochs 2 \
--save_images_epochs 2 \
--num_train_steps 1000 \
--num_inference_steps 1000 \
--train_scheduler ddpm \
--test_scheduler ddpm \



In particular, I want to cycle through these variable combinations

dataset_name: /home/th716/rds/hpc-work/audio-diffusion/cache/musiccaps/mel_spec_64_64
output_dir: /home/th716/rds/hpc-work/audio-diffusion/models/musiccaps_64_64

dataset_name: /home/th716/rds/hpc-work/audio-diffusion/cache/drum_samples/mel_spec_64_64
output_dir: /home/th716/rds/hpc-work/audio-diffusion/models/drum_samples_64_64

dataset_name: /home/th716/rds/hpc-work/audio-diffusion/cache/spotify_sleep_dataset/mel_spec_64_64
output_dir: /home/th716/rds/hpc-work/audio-diffusion/models/spotify_sleep_dataset_64_64



dataset_name: /home/th716/rds/hpc-work/audio-diffusion/cache/musiccaps/mel_spec_256_256
output_dir: /home/th716/rds/hpc-work/audio-diffusion/models/musiccaps_256_256

dataset_name: /home/th716/rds/hpc-work/audio-diffusion/cache/drum_samples/mel_spec_256_256
output_dir: /home/th716/rds/hpc-work/audio-diffusion/models/drum_samples_256_256

dataset_name: /home/th716/rds/hpc-work/audio-diffusion/cache/spotify_sleep_dataset/mel_spec_256_256
output_dir: /home/th716/rds/hpc-work/audio-diffusion/models/spotify_sleep_dataset_256_256

=================================================================================

conversion of mel-spectrograms to audio
models to use:
- bigvgan_base_24khz_100band
- bigvgan_24khz_100band
- bigvgan_v2_44khz_128band_256x
- griffin-lim algorithm

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 16 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_22khz \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_22khz/converted_audio_gl16 \
    --hop_length 256 \
    --n_fft 1024 \
    --sample_rate 22050 \
    > logs/gl16_sr22k.log 2>&1 &

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 32 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_22khz \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_22khz/converted_audio_gl32 \
    --hop_length 256 \
    --n_fft 1024 \
    --sample_rate 22050 \
    > logs/gl32_sr22k.log 2>&1 &

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 64 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_22khz \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_22khz/converted_audio_gl64 \
    --hop_length 256 \
    --n_fft 1024 \
    --sample_rate 22050 \
    > logs/gl64_sr22k.log 2>&1 &

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 128 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_22khz \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_22khz/converted_audio_gl128 \
    --hop_length 256 \
    --n_fft 1024 \
    --sample_rate 22050 \
    > logs/gl128_sr22k.log 2>&1 &

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 16 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_44khz \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_44khz/converted_audio_gl16 \
    --hop_length 256 \
    --n_fft 1024 \
    --sample_rate 44100 \
    > logs/gl16_sr44k.log 2>&1 &

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 32 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_44khz \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_44khz/converted_audio_gl32 \
    --hop_length 256 \
    --n_fft 1024 \
    --sample_rate 44100 \
    > logs/gl32_sr44k.log 2>&1 &

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 64 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_44khz \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_44khz/converted_audio_gl64 \
    --hop_length 256 \
    --n_fft 1024 \
    --sample_rate 44100 \
    > logs/gl64_sr44k.log 2>&1 &

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 128 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_44khz \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_selection_1024/mel_spec_44khz/converted_audio_gl128 \
    --hop_length 256 \
    --n_fft 1024 \
    --sample_rate 44100 \
    > logs/gl128_sr44k.log 2>&1 &

=================================================================================

Evaluate a generated set with a reference set.
Below are experiments for the incremental evaluation of various ground-truth back-converted

TODO
Continue from here, figure out why the command is not working. Is it an environment thing?
This has been done on the HPC


nohup python scripts/evaluation.py \
    --reference_paths cache/spotify_sleep_dataset/waveform \
    cache/fma_pop/waveform \
    cache/musiccaps/waveform \
    --generated_path cache/spotify_sleep_dataset/waveform_selection_1024/bigvgan_24khz_100band/converted_audio \
    --metric frechet_audio_distance \
    --model_names clap-laion-audio clap-laion-music vggish \
    --log_dir models/evaluation \
    > logs/incr_eval_bigvgan_24khz_100band.log 2>&1 &


=================================================================================

Mel Spectrograms to Audio for mel-spec variables experiments

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 32 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_1024/mel_spec_512_128_hl_64_nfft_256 \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_1024/mel_spec_512_128_hl_64_nfft_256/converted_gl32 \
    --hop_length 64 \
    --n_fft 256 \
    --sample_rate 22050 \
    > logs/hl64_nfft256_gl32.log 2>&1 &

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 32 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_1024/mel_spec_512_128_hl_64_nfft_512 \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_1024/mel_spec_512_128_hl_64_nfft_512/converted_gl32 \
    --hop_length 64 \
    --n_fft 512 \
    --sample_rate 22050 \
    > logs/hl64_nfft512_gl32.log 2>&1 &

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 32 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_1024/mel_spec_512_128_hl_64_nfft_1024 \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_1024/mel_spec_512_128_hl_64_nfft_1024/converted_gl32 \
    --hop_length 64 \
    --n_fft 1024 \
    --sample_rate 22050 \
    > logs/hl64_nfft1024_gl32.log 2>&1 &

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 32 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_1024/mel_spec_512_128_hl_64_nfft_2048 \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_1024/mel_spec_512_128_hl_64_nfft_2048/converted_gl32 \
    --hop_length 64 \
    --n_fft 2048 \
    --sample_rate 22050 \
    > logs/hl64_nfft2048_gl32.log 2>&1 &

nohup python3 scripts/mel_to_audio_conversion.py \
    --generation_method image \
    --griffin_lim_iters 32 \
    --num_samples 1024 \
    --mel_spec_path /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_1024/mel_spec_512_128_hl_64_nfft_4096 \
    --output_dir /home/th716/audio-diffusion/cache/spotify_sleep_dataset/waveform_1024/mel_spec_512_128_hl_64_nfft_4096/converted_gl32 \
    --hop_length 64 \
    --n_fft 4096 \
    --sample_rate 22050 \
    > logs/hl64_nfft4096_gl32.log 2>&1 &